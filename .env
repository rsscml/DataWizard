# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=False
SECRET_KEY=flask-secret-key

# OnlyOffice Configuration
#ONLYOFFICE_SERVER_URL=https://ai-ods-demo.azurewebsites.net
ONLYOFFICE_SERVER_URL=http://172.17.148.0:8080
ONLYOFFICE_CALLBACK_URL=http://localhost:5000/onlyoffice/callback

# Optional: JWT Configuration for OnlyOffice (Production)
ONLYOFFICE_JWT_SECRET=your-jwt-secret-key
ONLYOFFICE_JWT_ENABLED=false

# Default database configuration
DATABRICKS_SERVER_HOSTNAME=adb-3174745552007013.13.azuredatabricks.net
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/75820ff6cda396ec
DATABRICKS_CATALOG=pds_cognitive_insights_930697_dev
DATABRICKS_SCHEMA=pmrs_reduced

# Azure Variables
AZURE_TENANT_ID=f66fae02-5d36-495b-bfe0-78a6ff9f8e6e
AZURE_CLIENT_ID=87725be9-76b9-46ce-8e24-eb81a59f5af9
AZURE_CLIENT_SECRET=waO8Q~2WJ9BQ2WclKwiEN7lBXb1wGPu7WMJHKb8r
SCOPE=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d/.default
SPN=svc-b-da-d-930697-ina-aadprincipal
SUBSCRIPTION_KEY=6e4956c3b8854fb191a43ea4b7a0c063
TOKEN_URL=https://login.microsoftonline.com/f66fae02-5d36-495b-bfe0-78a6ff9f8e6e/oauth2/v2.0/token
AZURE_OPENAI_BASE_URL=https://bnlwe-ai03-q-931039-apim-01.azure-api.net
MODEL_VERSION=2024-11-20

# Database configuration file (optional)
DATABASE_CONFIG_FILE=database_configs.json

# LLM Provider Selection (azure_openai, openai, claude, gemini)
LLM_PROVIDER=claude

# OpenAI Configuration
# snapshot gpt-5-mini-2025-08-07
OPENAI_API_KEY=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
OPENAI_MODEL=gpt-5-mini
OPENAI_MAX_TOKENS=16000

# Claude Configuration
ANTHROPIC_API_KEY=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
CLAUDE_MODEL=claude-sonnet-4-20250514
CLAUDE_MAX_TOKENS=16000

# Gemini Configuration
GOOGLE_API_KEY=your-google-api-key
GEMINI_MODEL=gemini-2.5-pro
GEMINI_MAX_TOKENS=16000

# General LLM Settings
LLM_TEMPERATURE=0.1
LLM_MAX_RETRIES=3
LLM_TIMEOUT=300
LLM_STREAMING=false

# Prompt Caching Configuration
LLM_ENABLE_CACHING=false

#LLM_CACHE_TTL=1800  # Cache TTL in seconds
#LLM_USE_CACHED_MODELS=true  # Use model variants optimized for caching

# Provider-specific caching settings
#ANTHROPIC_CACHE_CONTROL=true
#OPENAI_SEED=42  # For deterministic outputs
#GEMINI_CACHE_CONTEXT=true

# Text Standardization Configuration (Conservative Mode)
TEXT_STANDARDIZATION_ENABLED=True
TEXT_STANDARDIZATION_THRESHOLD=95  # Very high threshold for safety
